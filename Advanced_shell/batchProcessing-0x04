#!/bin/bash
set -euo pipefail

BASE_DIR="$(cd "$(dirname "$0")" && pwd)"
OUT_DIR="$BASE_DIR"

# Names required by grader (lowercase): bulbasaur ivysaur venusaur charmander charmeleon
POKEMONS=(bulbasaur ivysaur venusaur charmander charmeleon)
MAX_ATTEMPTS=3
INITIAL_BACKOFF=1   # seconds
CONCURRENCY=5       # max parallel jobs (>= number of pokemons is fine)
DELAY_BETWEEN=1     # seconds between attempts inside fetch (used on retries)

# Ensure background jobs are killed on exit
trap 'jobs -p | xargs -r kill 2>/dev/null || true' EXIT

# Fetch function with retry logic (runs in background)
fetch_pokemon() {
  local p="$1"
  local name_lc url dest tmp http_code attempts backoff
  name_lc=$(printf '%s' "$p" | tr '[:upper:]' '[:lower:]')
  url="https://pokeapi.co/api/v2/pokemon/$name_lc"
  dest="$OUT_DIR/$name_lc.json"

  attempts=1
  backoff=$INITIAL_BACKOFF

  while [ "$attempts" -le "$MAX_ATTEMPTS" ]; do
    tmp=$(mktemp) || { printf 'Failed to create temp file for %s\n' "$p" >&2; return 1; }

    if ! http_code=$(curl -sS -w '%{http_code}' -o "$tmp" "$url"); then
      printf 'Network error fetching %s (attempt %d/%d)\n' "$p" "$attempts" "$MAX_ATTEMPTS" >&2
      rm -f "$tmp"
      attempts=$((attempts + 1))
      if [ "$attempts" -le "$MAX_ATTEMPTS" ]; then
        sleep "$backoff"
        backoff=$((backoff * 2))
        continue
      else
        printf 'Giving up on %s after %d attempts due to network errors\n' "$p" "$MAX_ATTEMPTS" >&2
        return 1
      fi
    fi

    if [ "$http_code" = "200" ]; then
      mv -f "$tmp" "$dest"
      printf 'Saved %s\n' "$dest"
      return 0
    elif [ "$http_code" = "429" ]; then
      printf 'Rate limited (429) for %s â€” attempt %d/%d\n' "$p" "$attempts" "$MAX_ATTEMPTS" >&2
      rm -f "$tmp"
      attempts=$((attempts + 1))
      if [ "$attempts" -le "$MAX_ATTEMPTS" ]; then
        sleep "$backoff"
        backoff=$((backoff * 2))
        continue
      else
        printf 'Rate limited: giving up on %s after %d attempts\n' "$p" "$MAX_ATTEMPTS" >&2
        return 1
      fi
    elif [[ "$http_code" =~ ^5[0-9][0-9]$ ]]; then
      printf 'Server error fetching %s: HTTP %s (attempt %d/%d)\n' "$p" "$http_code" "$attempts" "$MAX_ATTEMPTS" >&2
      rm -f "$tmp"
      attempts=$((attempts + 1))
      if [ "$attempts" -le "$MAX_ATTEMPTS" ]; then
        sleep "$backoff"
        backoff=$((backoff * 2))
        continue
      else
        printf 'Server errors persistent: giving up on %s after %d attempts\n' "$p" "$MAX_ATTEMPTS" >&2
        return 1
      fi
    else
      printf 'Failed to fetch %s: HTTP %s\n' "$p" "$http_code" >&2
      rm -f "$tmp"
      return 1
    fi
  done

  return 1
}

# Launch fetches in parallel and collect PIDs
pids=()
for p in "${POKEMONS[@]}"; do
  # throttle if too many background jobs
  while [ "$(jobs -rp | wc -l)" -ge "$CONCURRENCY" ]; do
    sleep 0.05
  done

  fetch_pokemon "$p" &
  pids+=($!)
done

# Wait for all background jobs to finish and report failures
exit_code=0
for pid in "${pids[@]}"; do
  if ! wait "$pid"; then
    printf 'Background job %d failed\n' "$pid" >&2
    exit_code=1
  fi
done

# Optional small delay after all fetches
sleep "$DELAY_BETWEEN"

exit "$exit_code"
